# Image Augmentation(이미지 증강)

## Image Augmentation (이미지 증강)

- 이미지 데이터를 인위적으로 변형하여 데이터 셋을 증강하는 방법
- 데이터 증강은 과적합을 방지하고, 모델의 일반화 성능을 높이는 데 도움이 된다
- 대표적인 방법으로는 회전, 이동, 확대/축소, 반전 등이 있다
- 딥러닝에서는 보통 이미지 데이터를 전처리할 때 이미지 증강 기법을 활용하여 일반화 성능을 향상시킨다
    - 예시
        - ImageDataGenrator : keras에서 제공하는 이미지 증강을 구현하기 위한 클래스
            - rotation_range : 이미지 회전 범위 (0~180)
            - width_shift_range : 이미지 가로 이동 범위 (실수, 비율)
            - height_shift_range : 이미지 세로 이동 범위 (실수, 비율)
            - shear_range : 밀림 강도 범위 (라디안)
            - zoom_range : 이미지 확대/축소 범위 (실수 또는 [하한, 상한] 구간)
            - horizontal_flip : 수평 뒤집기 여부 (불리언)
            - vertical_flip : 수직 뒤집기 여부 (불리언)
            - rescale : 이미지 스케일링 (0~1 사이의 실수)
- 이미지 증강법 예시
    - ImageDetaGenerator : keras에서 제공하는 이미지 데이터 증강을 위한 클래스
        - 파라미터
            - `featurewise_center`: 데이터 셋 전체의 평균을 0으로 만들기 위해 사용되는 boolean 값
            - `featurewise_std_normalization`: 데이터 셋 전체의 표준편차를 1로 만들기 위해 사용되는 boolean 값
            - `rotation_range`: 이미지 회전 범위 (0-180)
            - `width_shift_range`: 좌/우로 이미지 이동 범위 (원래 이미지 너비에 대한 비율)
            - `height_shift_range`: 상/하로 이미지 이동 범위 (원래 이미지 높이에 대한 비율)
            - `shear_range`: 전단 변환 범위 (반시계 방향으로 각도)
            - `zoom_range`: 무작위 확대/축소 범위
            - `horizontal_flip`: 이미지를 무작위로 수평 반전하는 boolean 값
            - `vertical_flip`: 이미지를 무작위로 수직 반전하는 boolean 값
    
    ![Untitled](image\2023_04_11\Untitled.png)
    
    ![Untitled](image\2023_04_11\Untitled1.png)
    
    이미지 임베드 크기를 줄이는 방법 중 하나는, 이미지를 적절한 크기로 리사이징하는 것입니다. 리사이징을 통해 이미지의 크기를 줄이면서도, 이미지의 중요한 정보를 유지할 수 있습니다. 예를 들어, keras에서는 `tf.keras.layers.experimental.preprocessing.Resizing` 레이어를 활용하여 이미지 리사이징을 할 수 있습니다.
    

![Untitled](image\2023_04_11\Untitled2.png)

![Untitled](image\2023_04_11\Untitled3.png)

# Transfer Learning (전이 학습)

- 기존 학습된 모델의 지식을 다른 문제에 적용하여 학습하는 방법
- 기존 모델에서 추출된 feature들을 새로운 모델에서 활용함으로써 데이터 셋의 크기가 작은 경우에도 좋은 결과를 얻을 수 있다
- 기존 모델이 잘 학습되어하며, 적용하려는 문제와 유사한 문제일 때만 적용 가능하다
- 전이 학습된 모델은 새로운 문제에 대해 일반적인 해결책을 제공하는 것이 아니라, 특정 문제에 대해서만 효과적이다

## Fine-tuning

- 전이 학습의 한 종류로, 기존 모델을 적용하고자 하는 새로운 문제에 맞게 재조정하는 것을 의미한다
- 기존 모델의 일부 층을 고정(freezing)하고, 나머지 층을 학습(fine-tuning)하는 방법을 사용한다
- 대부분의 경우, 사전 학습된 모델의 높은 성능을 유지하면서 새로운 문제에 적용할 수 있다
- 주로 새로운 문제가 기존 모델에서 다루는 문제와 유사하거나, 기존 모델이 학습한 feature들이 새로운 문제에서도 유용할 때 사용한다
- 일반적으로 fine-tuning은 새로운 데이터셋이 크거나, 원본 데이터셋과 유사한 경우에 효과적이다
- 사용되는 하이퍼 파라미터
    - `epochs`: 전체 데이터셋에 대해 학습을 반복하는 횟수
    - `batch_size`: 한 번에 모델에 입력되는 데이터 샘플의 개수
    - `learning_rate`: 모델이 학습할 때 사용하는 학습률
    - `optimizer`: 학습 중 가중치를 최적화하는 알고리즘
    - `loss`: 학습 중 모델의 성능을 측정하는 함수
    - `metrics`: 모델의 성능을 평가하는 지표
        
        ![Untitled](image\2023_04_11\Untitled4.png)
        
    - `trainable_layers`: fine-tuning을 할 때 어떤 층을 학습시킬 것인지를 결정하는 파라미터입니다. 이 값은 보통 사전 학습된 모델에서 일부 층을 고정하고, 나머지 층만 학습하는 방식으로 결정됩니다.
        - conv_base.layers[:-4] 까지 학습하지 않토록 설정한다.

        ![Untitled](image\2023_04_11\Untitled5.png)